{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "190030619_SC Lab 6",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBfj1aZFPu4h"
      },
      "source": [
        "##SC LAB -6\n",
        "##NAME : Jakkampudi Greeshma\n",
        "##ID : 190030619"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xxCAHsz51jJ"
      },
      "source": [
        "## Inlab 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-WlWrBO53-S"
      },
      "source": [
        "\n",
        "Using Binary Sigmoidal Function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtJ-2md04gOt",
        "outputId": "d598a30c-9c22-47bb-92ae-3dc82b666440"
      },
      "source": [
        "import numpy as np\n",
        "import sympy as sp\n",
        "import math\n",
        "x1=0.5\n",
        "x2=0.9\n",
        "x3=0.2\n",
        "x4=0.3\n",
        "b1,b_w=1,0.5\n",
        "#initializing the learning rate\n",
        "temp=0.3\n",
        "#initializing the input weights\n",
        "w1=0.2\n",
        "w2=0.3\n",
        "w3=-0.6\n",
        "w4=-0.1\n",
        "for i in range(0,1):\n",
        "    z1=x1*w1+x2*w2+x3*w3+x4*w4+b1*b_w\n",
        "    outz1=1/(1+math.exp(-z1))\n",
        "print('The output of z1 using binary sigmoidal is :',outz1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output of z1 using binary sigmoidal is : 0.6726070170677604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO2hCdQD58FK"
      },
      "source": [
        "Using Bipolar Sigmoidal Function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9M6DGkf5_Lj",
        "outputId": "a1fe6d6e-6532-4bba-e702-1db7f55b62b2"
      },
      "source": [
        "import numpy as np\n",
        "import sympy as sp\n",
        "import math\n",
        "x1=0.5\n",
        "x2=0.9\n",
        "x3=0.25\n",
        "x4=0.3\n",
        "b1,b_w=1,0.5\n",
        "#initializing the learning rate\n",
        "temp=0.3\n",
        "#initializing the input weights\n",
        "w1=0.2\n",
        "w2=0.3\n",
        "w3=-0.6\n",
        "w4=-0.1\n",
        "for i in range(0,1):\n",
        "    #calculating net input for hidden layer z1\n",
        "    z1=x1*w1+x2*w2+x3*w3+x4*w4+b1*b_w\n",
        "    outz1=2/(1+math.exp(-z1))\n",
        "print('The output of z1 using bipolar sigmoidal is:',outz1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output of z1 using bipolar sigmoidal is: 1.3319338535036405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_9kUzWa7U_f"
      },
      "source": [
        "## Inlab 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlBHqeyM7W6r"
      },
      "source": [
        "https://drive.google.com/file/d/1FpFm7zdrbho_0wVflZoTAkAh6gM-jSc4/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCXmyQwG7aAv",
        "outputId": "a26757cb-a287-4552-8669-fa9d410dfaf4"
      },
      "source": [
        "from numpy import loadtxt\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "dataset = np.loadtxt('/content/diabetes-1.csv', delimiter=',')\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
        "predictions=np.argmax(model.predict(X), axis=-1) \n",
        "for i in range(5):\n",
        "  print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 0 (expected 1)\n",
            "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
            "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 0 (expected 1)\n",
            "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
            "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 0 (expected 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkK2hJiP8M6M"
      },
      "source": [
        "##Postlab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gW0dt808Oxr"
      },
      "source": [
        "https://drive.google.com/file/d/1XjDR57oiYNBuav0uc2ue-sff_vSQie6T/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7D-cjO8z8Pq_",
        "outputId": "c618e074-b750-4ee7-f772-c0150c91504c"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "import seaborn as sns\n",
        "df = pd.read_csv('Dataset_spine.csv')\n",
        "df = df.drop(['Unnamed: 13'], axis=1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Col1</th>\n",
              "      <th>Col2</th>\n",
              "      <th>Col3</th>\n",
              "      <th>Col4</th>\n",
              "      <th>Col5</th>\n",
              "      <th>Col6</th>\n",
              "      <th>Col7</th>\n",
              "      <th>Col8</th>\n",
              "      <th>Col9</th>\n",
              "      <th>Col10</th>\n",
              "      <th>Col11</th>\n",
              "      <th>Col12</th>\n",
              "      <th>Class_att</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63.027818</td>\n",
              "      <td>22.552586</td>\n",
              "      <td>39.609117</td>\n",
              "      <td>40.475232</td>\n",
              "      <td>98.672917</td>\n",
              "      <td>-0.254400</td>\n",
              "      <td>0.744503</td>\n",
              "      <td>12.5661</td>\n",
              "      <td>14.5386</td>\n",
              "      <td>15.30468</td>\n",
              "      <td>-28.658501</td>\n",
              "      <td>43.5123</td>\n",
              "      <td>Abnormal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39.056951</td>\n",
              "      <td>10.060991</td>\n",
              "      <td>25.015378</td>\n",
              "      <td>28.995960</td>\n",
              "      <td>114.405425</td>\n",
              "      <td>4.564259</td>\n",
              "      <td>0.415186</td>\n",
              "      <td>12.8874</td>\n",
              "      <td>17.5323</td>\n",
              "      <td>16.78486</td>\n",
              "      <td>-25.530607</td>\n",
              "      <td>16.1102</td>\n",
              "      <td>Abnormal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68.832021</td>\n",
              "      <td>22.218482</td>\n",
              "      <td>50.092194</td>\n",
              "      <td>46.613539</td>\n",
              "      <td>105.985135</td>\n",
              "      <td>-3.530317</td>\n",
              "      <td>0.474889</td>\n",
              "      <td>26.8343</td>\n",
              "      <td>17.4861</td>\n",
              "      <td>16.65897</td>\n",
              "      <td>-29.031888</td>\n",
              "      <td>19.2221</td>\n",
              "      <td>Abnormal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>69.297008</td>\n",
              "      <td>24.652878</td>\n",
              "      <td>44.311238</td>\n",
              "      <td>44.644130</td>\n",
              "      <td>101.868495</td>\n",
              "      <td>11.211523</td>\n",
              "      <td>0.369345</td>\n",
              "      <td>23.5603</td>\n",
              "      <td>12.7074</td>\n",
              "      <td>11.42447</td>\n",
              "      <td>-30.470246</td>\n",
              "      <td>18.8329</td>\n",
              "      <td>Abnormal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49.712859</td>\n",
              "      <td>9.652075</td>\n",
              "      <td>28.317406</td>\n",
              "      <td>40.060784</td>\n",
              "      <td>108.168725</td>\n",
              "      <td>7.918501</td>\n",
              "      <td>0.543360</td>\n",
              "      <td>35.4940</td>\n",
              "      <td>15.9546</td>\n",
              "      <td>8.87237</td>\n",
              "      <td>-16.378376</td>\n",
              "      <td>24.9171</td>\n",
              "      <td>Abnormal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Col1       Col2       Col3  ...      Col11    Col12  Class_att\n",
              "0  63.027818  22.552586  39.609117  ... -28.658501  43.5123   Abnormal\n",
              "1  39.056951  10.060991  25.015378  ... -25.530607  16.1102   Abnormal\n",
              "2  68.832021  22.218482  50.092194  ... -29.031888  19.2221   Abnormal\n",
              "3  69.297008  24.652878  44.311238  ... -30.470246  18.8329   Abnormal\n",
              "4  49.712859   9.652075  28.317406  ... -16.378376  24.9171   Abnormal\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "RJjpVjUw84lO",
        "outputId": "2ad4a8ba-5590-4dfa-b349-9455765b469e"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Col1</th>\n",
              "      <th>Col2</th>\n",
              "      <th>Col3</th>\n",
              "      <th>Col4</th>\n",
              "      <th>Col5</th>\n",
              "      <th>Col6</th>\n",
              "      <th>Col7</th>\n",
              "      <th>Col8</th>\n",
              "      <th>Col9</th>\n",
              "      <th>Col10</th>\n",
              "      <th>Col11</th>\n",
              "      <th>Col12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>310.000000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>310.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>60.496653</td>\n",
              "      <td>17.542822</td>\n",
              "      <td>51.930930</td>\n",
              "      <td>42.953831</td>\n",
              "      <td>117.920655</td>\n",
              "      <td>26.296694</td>\n",
              "      <td>0.472979</td>\n",
              "      <td>21.321526</td>\n",
              "      <td>13.064511</td>\n",
              "      <td>11.933317</td>\n",
              "      <td>-14.053139</td>\n",
              "      <td>25.645981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>17.236520</td>\n",
              "      <td>10.008330</td>\n",
              "      <td>18.554064</td>\n",
              "      <td>13.423102</td>\n",
              "      <td>13.317377</td>\n",
              "      <td>37.559027</td>\n",
              "      <td>0.285787</td>\n",
              "      <td>8.639423</td>\n",
              "      <td>3.399713</td>\n",
              "      <td>2.893265</td>\n",
              "      <td>12.225582</td>\n",
              "      <td>10.450558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>26.147921</td>\n",
              "      <td>-6.554948</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.366931</td>\n",
              "      <td>70.082575</td>\n",
              "      <td>-11.058179</td>\n",
              "      <td>0.003220</td>\n",
              "      <td>7.027000</td>\n",
              "      <td>7.037800</td>\n",
              "      <td>7.030600</td>\n",
              "      <td>-35.287375</td>\n",
              "      <td>7.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>46.430294</td>\n",
              "      <td>10.667069</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>33.347122</td>\n",
              "      <td>110.709196</td>\n",
              "      <td>1.603727</td>\n",
              "      <td>0.224367</td>\n",
              "      <td>13.054400</td>\n",
              "      <td>10.417800</td>\n",
              "      <td>9.541140</td>\n",
              "      <td>-24.289522</td>\n",
              "      <td>17.189075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>58.691038</td>\n",
              "      <td>16.357689</td>\n",
              "      <td>49.562398</td>\n",
              "      <td>42.404912</td>\n",
              "      <td>118.268178</td>\n",
              "      <td>11.767934</td>\n",
              "      <td>0.475989</td>\n",
              "      <td>21.907150</td>\n",
              "      <td>12.938450</td>\n",
              "      <td>11.953835</td>\n",
              "      <td>-14.622856</td>\n",
              "      <td>24.931950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>72.877696</td>\n",
              "      <td>22.120395</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>52.695888</td>\n",
              "      <td>125.467674</td>\n",
              "      <td>41.287352</td>\n",
              "      <td>0.704846</td>\n",
              "      <td>28.954075</td>\n",
              "      <td>15.889525</td>\n",
              "      <td>14.371810</td>\n",
              "      <td>-3.497094</td>\n",
              "      <td>33.979600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>129.834041</td>\n",
              "      <td>49.431864</td>\n",
              "      <td>125.742385</td>\n",
              "      <td>121.429566</td>\n",
              "      <td>163.071041</td>\n",
              "      <td>418.543082</td>\n",
              "      <td>0.998827</td>\n",
              "      <td>36.743900</td>\n",
              "      <td>19.324000</td>\n",
              "      <td>16.821080</td>\n",
              "      <td>6.972071</td>\n",
              "      <td>44.341200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Col1        Col2        Col3  ...       Col10       Col11       Col12\n",
              "count  310.000000  310.000000  310.000000  ...  310.000000  310.000000  310.000000\n",
              "mean    60.496653   17.542822   51.930930  ...   11.933317  -14.053139   25.645981\n",
              "std     17.236520   10.008330   18.554064  ...    2.893265   12.225582   10.450558\n",
              "min     26.147921   -6.554948   14.000000  ...    7.030600  -35.287375    7.007900\n",
              "25%     46.430294   10.667069   37.000000  ...    9.541140  -24.289522   17.189075\n",
              "50%     58.691038   16.357689   49.562398  ...   11.953835  -14.622856   24.931950\n",
              "75%     72.877696   22.120395   63.000000  ...   14.371810   -3.497094   33.979600\n",
              "max    129.834041   49.431864  125.742385  ...   16.821080    6.972071   44.341200\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pPS1ODK87mu"
      },
      "source": [
        "df = df.drop(['Col7','Col8','Col9','Col10','Col11','Col12'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRtRCnSm8-mO",
        "outputId": "6db78cdb-eab8-4472-8e06-db55bc76f3b7"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y = df['Class_att']\n",
        "x = df.drop(['Class_att'], axis=1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.25, random_state=27)\n",
        "clf = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=500, alpha=0.0001,\n",
        "                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n",
        "clf.fit(x_train, y_train)\n",
        "y_pred = clf.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 8.74253469\n",
            "Iteration 3, loss = 1.55562179\n",
            "Iteration 4, loss = 0.94416556\n",
            "Iteration 5, loss = 1.50851327\n",
            "Iteration 6, loss = 0.50784081\n",
            "Iteration 7, loss = 0.39918410\n",
            "Iteration 8, loss = 0.37867398\n",
            "Iteration 9, loss = 0.37472479\n",
            "Iteration 10, loss = 0.34567928\n",
            "Iteration 11, loss = 0.34293793\n",
            "Iteration 12, loss = 0.33180054\n",
            "Iteration 13, loss = 0.33138624\n",
            "Iteration 14, loss = 0.32280653\n",
            "Iteration 15, loss = 0.32238711\n",
            "Iteration 16, loss = 0.33164385\n",
            "Iteration 17, loss = 0.31229600\n",
            "Iteration 18, loss = 0.30823387\n",
            "Iteration 19, loss = 0.32317560\n",
            "Iteration 20, loss = 0.30697614\n",
            "Iteration 21, loss = 0.30901736\n",
            "Iteration 22, loss = 0.35327698\n",
            "Iteration 23, loss = 0.31835192\n",
            "Iteration 24, loss = 0.30599160\n",
            "Iteration 25, loss = 0.30315921\n",
            "Iteration 26, loss = 0.30774646\n",
            "Iteration 27, loss = 0.30939928\n",
            "Iteration 28, loss = 0.30205629\n",
            "Iteration 29, loss = 0.30492366\n",
            "Iteration 30, loss = 0.30627954\n",
            "Iteration 31, loss = 0.32245209\n",
            "Iteration 32, loss = 0.30092367\n",
            "Iteration 33, loss = 0.32289947\n",
            "Iteration 34, loss = 0.30300054\n",
            "Iteration 35, loss = 0.29623179\n",
            "Iteration 36, loss = 0.29708219\n",
            "Iteration 37, loss = 0.30250871\n",
            "Iteration 38, loss = 0.29467717\n",
            "Iteration 39, loss = 0.29677633\n",
            "Iteration 40, loss = 0.29248421\n",
            "Iteration 41, loss = 0.29520714\n",
            "Iteration 42, loss = 0.34293079\n",
            "Iteration 43, loss = 0.29191404\n",
            "Iteration 44, loss = 0.29066025\n",
            "Iteration 45, loss = 0.29314507\n",
            "Iteration 46, loss = 0.30713375\n",
            "Iteration 47, loss = 0.28961352\n",
            "Iteration 48, loss = 0.29269266\n",
            "Iteration 49, loss = 0.35675684\n",
            "Iteration 50, loss = 0.29497979\n",
            "Iteration 51, loss = 0.32161702\n",
            "Iteration 52, loss = 0.31725676\n",
            "Iteration 53, loss = 0.28841341\n",
            "Iteration 54, loss = 0.32379049\n",
            "Iteration 55, loss = 0.30023310\n",
            "Iteration 56, loss = 0.30758373\n",
            "Iteration 57, loss = 0.29833024\n",
            "Iteration 58, loss = 0.30977012\n",
            "Iteration 59, loss = 0.28748498\n",
            "Iteration 60, loss = 0.30416906\n",
            "Iteration 61, loss = 0.31005774\n",
            "Iteration 62, loss = 0.29357602\n",
            "Iteration 63, loss = 0.29838988\n",
            "Iteration 64, loss = 0.28817921\n",
            "Iteration 65, loss = 0.31316590\n",
            "Iteration 66, loss = 0.28847521\n",
            "Iteration 67, loss = 0.28735284\n",
            "Iteration 68, loss = 0.29273707\n",
            "Iteration 69, loss = 0.31120553\n",
            "Iteration 70, loss = 0.28602647\n",
            "Iteration 71, loss = 0.28878231\n",
            "Iteration 72, loss = 0.28673847\n",
            "Iteration 73, loss = 0.29844198\n",
            "Iteration 74, loss = 0.28573291\n",
            "Iteration 75, loss = 0.28849915\n",
            "Iteration 76, loss = 0.30711551\n",
            "Iteration 77, loss = 0.28537053\n",
            "Iteration 78, loss = 0.28906500\n",
            "Iteration 79, loss = 0.31497841\n",
            "Iteration 80, loss = 0.32441142\n",
            "Iteration 81, loss = 0.30927713\n",
            "Iteration 82, loss = 0.28468929\n",
            "Iteration 83, loss = 0.28284050\n",
            "Iteration 84, loss = 0.28486940\n",
            "Iteration 85, loss = 0.28324834\n",
            "Iteration 86, loss = 0.28635970\n",
            "Iteration 87, loss = 0.28255922\n",
            "Iteration 88, loss = 0.28968301\n",
            "Iteration 89, loss = 0.28914169\n",
            "Iteration 90, loss = 0.41232697\n",
            "Iteration 91, loss = 0.33779084\n",
            "Iteration 92, loss = 0.30298213\n",
            "Iteration 93, loss = 0.29320069\n",
            "Iteration 94, loss = 0.28770790\n",
            "Iteration 95, loss = 0.29386661\n",
            "Iteration 96, loss = 0.30271605\n",
            "Iteration 97, loss = 0.31373311\n",
            "Iteration 98, loss = 0.28213563\n",
            "Iteration 99, loss = 0.32039083\n",
            "Iteration 100, loss = 0.28225381\n",
            "Iteration 101, loss = 0.28239536\n",
            "Iteration 102, loss = 0.28888423\n",
            "Iteration 103, loss = 0.40146253\n",
            "Iteration 104, loss = 0.28481547\n",
            "Iteration 105, loss = 0.28301174\n",
            "Iteration 106, loss = 0.28824478\n",
            "Iteration 107, loss = 0.28220960\n",
            "Iteration 108, loss = 0.29126322\n",
            "Iteration 109, loss = 0.28446019\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L18F-eQn9EgP",
        "outputId": "d7a6873e-1154-48d8-ceef-f97bbe4d1e2f"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7948717948717948"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SweEwEsk9Iwv",
        "outputId": "d01d863a-775b-4aca-cebd-6506cb583e34"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[40, 13],\n",
              "       [ 3, 22]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "W-IL2jpx9LXG",
        "outputId": "e1921734-a41b-47f2-9de8-172df0d64a19"
      },
      "source": [
        "sns.heatmap(cm, center=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}